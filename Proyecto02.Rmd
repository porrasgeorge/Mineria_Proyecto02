---
title: "Proyecto 02"
author: "Jorge Porras & Alex Cruz"
date: "12/4/2020"
output:
  pdf_document: default
  html_document: default
---

# ¿Es posible predecir desbalances de tension?

## ¿Por que no usar series de tiempo?
#### huecos en las mediciones (faltantes)



#### Carga de librerias

```{r}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
#library(RODBC)
library(lubridate)
library(feather)
library(ggplot2)
library(tidyr)
library(caTools)
library(randomForest)
library(caret)
library(e1071)
library(mltest)
```

#### Rango de fechas (lubridate)

```{r}
final_dateCR <- floor_date(now(), "week") + days(1) ## primer lunes hacia atras
initial_dateCR <- final_dateCR - years(3) ## 3 años hacia atras 
```

#### Fecha-hora a UTC (lubridate) (DB está en UTC)

```{r}
initial_date <- with_tz(initial_dateCR, tzone = "UTC") 
final_date <- with_tz(final_dateCR, tzone = "UTC") 
```

#### Valores Nominales (vectores)

```{r}
nom_voltage <- 35000
cut_voltage <- 34000
clasif <- c("Low" = 0.3,
                     "Low_Mid" = 0.5,
                     "Mid" = 0.7,
                     "Mid_High" = 0.9,
                     "High" = 1.1)

```

#### Conexion a SQL Server y carga de tablas (RODBC)

```{r eval = FALSE}
channel <- odbcConnect("SQL_ION", uid="sa", pwd="Con3$adm.")
#sources <- sqlQuery(channel , "select top 100 ID, Name, DisplayName from Source where Name like 'Coopeguanacaste.%'")
sources <- sqlQuery(channel , "select top 100 ID, Name, DisplayName from Source where Name like 'Coopealfaroruiz.%'")
#sources$Name <- gsub("Coopeguanacaste.", '', sources$Name)
sources$Name <- gsub("Coopealfaroruiz.", '', sources$Name)l
sources <- sources %>% filter(ID %in% c(9))

quantity <- sqlQuery(channel , "select top 1500000 ID, Name from Quantity where Name like 'Voltage%'")
quantity <- quantity %>% filter(grepl("^Voltage Phases [ABC][ABC] Mean$", Name))
quantity$Name <- c('Vab', 'Vbc', 'Vca')

sources_ids <- paste0(sources$ID, collapse = ",")
quantity_ids <- paste0(quantity$ID, collapse = ",")
dataLog <- sqlQuery(channel , paste0("select top 500000 * from dataLog2 where ",
                                      "SourceID in (", sources_ids, ")",
                                      " and QuantityID in (", quantity_ids, ")",
                                      " and TimestampUTC >= '", initial_date, "'",
                                      " and TimestampUTC < '", final_date, "'"))

odbcCloseAll()

```

#### Guardar archivos con las tablas

```{r eval = FALSE}
#write_feather(dataLog, "featherFiles/dataLog.feather")
#write_feather(quantity, "featherFiles/quantity.feather")
#write_feather(sources, "featherFiles/sources.feather")
```

#### Leer Archivos de las tablas

```{r}
#rm(dataLog, quantity, sources)
dataLog  <- read_feather("featherFiles/dataLog.feather")
quantity <- read_feather("featherFiles/quantity.feather")
sources  <- read_feather("featherFiles/sources.feather")
```


### Contenido de las tablas

#### Datalog

```{r}
glimpse(dataLog)
```

#### Quantity

```{r}
glimpse(quantity)
```

#### Sources

```{r}
glimpse(sources)
```

#### Transformacion de datos para analisis previo

#### Union de tablas, borrado de columnas no importantes y Categorizacion de valores

```{r}
## Transformacion de columnas
dataLog$TimestampUTC <- as_datetime(dataLog$TimestampUTC)
dataLog$TimestampCR <- with_tz(dataLog$TimestampUTC, tzone = "America/Costa_Rica") 
dataLog$TimestampUTC <- NULL
dataLog$ID <- NULL
dataLog$year <- year(dataLog$TimestampCR)
dataLog$month <- month(dataLog$TimestampCR)
dataLog$day <- day(dataLog$TimestampCR)
dataLog$hour <- hour(dataLog$TimestampCR)
dataLog$minute <- minute(dataLog$TimestampCR)
dataLog$wday <- wday(dataLog$TimestampCR)
dataLog$wdayName <- weekdays(dataLog$TimestampCR)
dataLog$monthName <- month.abb[dataLog$month]

dataLog$hour2 <- hour(dataLog$TimestampCR)+ (minute(dataLog$TimestampCR)/60)

dataLog <- dataLog %>% left_join(quantity, by = c('QuantityID' = "ID")) %>%
  left_join(sources, by = c('SourceID' = "ID"))

names(dataLog)[names(dataLog) == "Name.x"] <- "Quantity"
names(dataLog)[names(dataLog) == "Name.y"] <- "Meter"

dataLog$SourceID <- NULL
dataLog$QuantityID <- NULL
dataLog$DisplayName <- NULL
#rm(quantity, sources)
```

#### Contenido de la tabla Datalog

```{r}
glimpse(dataLog)
```

## Análisis de datos
### Histogramas y boxplots

#### Cantidad de filas inicial

```{r}
initial_rows <- nrow(dataLog)
initial_rows
```

#### Boxplot del comportamiento de la tension (horizontal)

```{r}
boxplot(dataLog$Value, xlab= "Voltaje", col="Orange", border = "brown", horizontal = T, main = "Voltaje Promedio") 
```

#### Histograma inicial

```{r}
hist(dataLog$Value, col="Orange", border = "brown", xlab = "Valor", ylab = "Frecuencia", main = "Histograma de Tension")

```

#### Variable temporal solo para análisis (originalmente se tenian 15825 rows)

```{r}
dl_temp <- dataLog %>% filter(Value > cut_voltage)
### Cantidad de filas
final_rows <- nrow(dl_temp)
print(paste0 ("Se eliminaron el ", round(100*((initial_rows - final_rows)/initial_rows), 2), "% de las filas" ))
```

#### Boxplot con un filtro temporal de los datos (para análisis unicamente)

```{r}
boxplot(dl_temp$Value, xlab= "Voltaje", col="Orange", border = "brown", horizontal = T, main = "Voltaje Promedio") 
```

#### Histograma eliminando outliers de la tabla temporal

```{r}
hist(dl_temp$Value, col="Orange", border = "brown", xlab = "Tension", ylab = "Frecuencia", breaks = 60, main = "Histograma de Tension")
```

#### Grafico de densidad

```{r}
d <- density(dl_temp$Value)
plot(d, main = "Densidad")
polygon(d, col = "Orange", border = "brown")
```

#### Boxplot separado por variable

```{r}

bp <- ggplot(dl_temp, aes(Quantity, Value))
bp <- bp + geom_boxplot(aes(colour = Quantity))
bp <- bp + scale_color_brewer(palette="Dark2")
bp

```

#### Grafico de densidad para cada variable

```{r}
lineas <- dl_temp %>% group_by(Quantity) %>% summarise(v = mean(Value))

p <- ggplot(dl_temp, aes(x=Value, fill = Quantity)) + 
  geom_density(alpha = 0.6) +
  geom_vline(data=lineas, aes(xintercept=v, color=Quantity), size = 2)
p
```

### Aqui inician la modificaciones reales de los datos

#### Pivot para generar columnas para las 3 variables de tension y eliminar los outliers, Cálculo del procentaje de desbalance y categoria del mismo

```{r}
## pivot respecto de Quantity
dataLog2 <- tidyr::spread(dataLog, Quantity, Value)

## filtro de valores menores al corte
dataLog2 <- dataLog2 %>% filter(Vab > cut_voltage, Vbc>cut_voltage, Vca > cut_voltage)

## definicion de metodos
## Calculo de desbalance maximo
unbal_calc  <- function(va, vb, vc){
  maximo =  pmax(abs(va-vb), abs(vb-vc), abs(vc-va))
  promedio = (va + vb + vc)/3
  unb <- 100*maximo/promedio
  return(unb)
}

## categoria del desbalance
unbal_categ  <- function(unb){
  unb_class <- case_when(unb < clasif["Low"] ~ "Low",
                      unb < clasif["Low_Mid"] ~ "Low_Mid",
                      unb < clasif["Mid"] ~ "Mid",
                      unb < clasif["Mid_High"] ~ "Mid_High",
                      unb < clasif["High"] ~ "High",
                      TRUE ~ "Very_High"
                      )
  return(unb_class)
} 

## nuevas columnas
dataLog2 <- dataLog2 %>% 
  mutate (unbalance = unbal_calc(Vab, Vbc, Vca)) %>% 
  mutate (unbal_cat = factor(unbal_categ(unbalance), levels = c("Low","Low_Mid","Mid","Mid_High","High","Very_High"))) %>%
  select (year, monthName, day, hour, minute, wdayName, unbalance, unbal_cat)

## converson de variables
dataLog2$year <- as.integer(dataLog2$year)
dataLog2$monthName <- factor(dataLog2$monthName, levels = month.abb[1:12])
dataLog2$day <- factor(dataLog2$day, levels = c(1:31))
dataLog2$hour <- factor(dataLog2$hour, levels = c(0:23))
dataLog2$minute <- factor(dataLog2$minute, levels = c(0, 15, 30, 45))
dataLog2$wdayName <- factor(dataLog2$wdayName)

## tabla resultado
glimpse(dataLog2)
```

#### tabla de conteo de elementos en cada categoria

```{r}
table(dataLog2$unbal_cat)

```




#### Desbalance promedio 

```{r}
a <- dataLog2 %>% group_by(hour, minute) %>% summarise(v = mean(unbalance))
ggplot(a, aes(hour, v)) + geom_point(aes(colour = minute)) + geom_line(col = "orange")

```



## Particionamiento de los datos

```{r}

dL <- dataLog2 %>% filter (year > 2017) %>% 
  select(-unbalance)

set.seed(4)
mascara <- sample.split(dL$unbal_cat, SplitRatio = 7/10)
training_data <- dL[mascara,]
test_data <- dL[!mascara,]

table(dL$unbal_cat)

```

```{r  eval = FALSE}
start_time <- Sys.time()

# modelo <- randomForest(formula = unbal_cat ~ .,
#                        data = training_data,
#                        mtry=2, ntree=1000,
#                        keep.forest=TRUE,
#                        importance=TRUE,
#                        test=test_data)
#saveRDS(modelo, file = "models/modelo2018.modelo")
#saveRDS(modelo, file = "models/modelo2017.modelo")


end_time <- Sys.time()
end_time - start_time

```

#### predicciones

```{r}
#modelo = readRDS(file = "models/modelo2018.modelo")
modelo = readRDS(file = "models/modelo2017.modelo")

pred <- predict(modelo, newdata = test_data)
pred_ROCR <-ml_test(pred, test_data$unbal_cat, output.as.table = TRUE)
glimpse(test_data)

```

#### Evaluar el modelo

```{r}
confusionMatrix(test_data$unbal_cat, pred)
```






