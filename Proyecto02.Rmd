---
title: "Proyecto 02"
author: "Jorge Porras & Alex Cruz"
date: "12/4/2020"
output:
  pdf_document: default
  html_document: default
---

# ¿Es posible predecir desbalances de tension?

#### Carga de librerias

```{r}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
#library(RODBC)
library(lubridate)
library(feather)
library(ggplot2)
library(tidyr)
library(caTools)
library(randomForest)
library(caret)
library(e1071)
#library(xlsx)
```

#### Rango de fechas (lubridate)

```{r}
final_dateCR <- floor_date(now(), "week") + days(1) ## primer lunes hacia atras
initial_dateCR <- final_dateCR - years(3) ## 3 años hacia atras 
```

#### Fecha-hora a UTC (lubridate) (DB está en UTC)

```{r}
initial_date <- with_tz(initial_dateCR, tzone = "UTC") 
final_date <- with_tz(final_dateCR, tzone = "UTC") 
```

#### Valores Nominales (vectores)

```{r}
nom_voltage <- 35000
cut_voltage <- 34000
clasif <- c("Low" = 0.3,
                     "Low_Mid" = 0.5,
                     "Mid" = 0.7,
                     "Mid_High" = 0.9,
                     "High" = 1.1)

```

#### Conexion a SQL Server y carga de tablas (RODBC)

```{r eval = FALSE}
channel <- odbcConnect("SQL_ION", uid="sa", pwd="Con3$adm.")
#sources <- sqlQuery(channel , "select top 100 ID, Name, DisplayName from Source where Name like 'Coopeguanacaste.%'")
sources <- sqlQuery(channel , "select top 100 ID, Name, DisplayName from Source where Name like 'Coopealfaroruiz.%'")
#sources$Name <- gsub("Coopeguanacaste.", '', sources$Name)
sources$Name <- gsub("Coopealfaroruiz.", '', sources$Name)l
sources <- sources %>% filter(ID %in% c(9))

quantity <- sqlQuery(channel , "select top 1500000 ID, Name from Quantity where Name like 'Voltage%'")
quantity <- quantity %>% filter(grepl("^Voltage Phases [ABC][ABC] Mean$", Name))
quantity$Name <- c('Vab', 'Vbc', 'Vca')

sources_ids <- paste0(sources$ID, collapse = ",")
quantity_ids <- paste0(quantity$ID, collapse = ",")
dataLog <- sqlQuery(channel , paste0("select top 500000 * from dataLog2 where ",
                                      "SourceID in (", sources_ids, ")",
                                      " and QuantityID in (", quantity_ids, ")",
                                      " and TimestampUTC >= '", initial_date, "'",
                                      " and TimestampUTC < '", final_date, "'"))

odbcCloseAll()

```

#### Guardar archivos con las tablas

```{r eval = FALSE}
#write_feather(dataLog, "featherFiles/dataLog.feather")
#write_feather(quantity, "featherFiles/quantity.feather")
#write_feather(sources, "featherFiles/sources.feather")
```

#### Leer Archivos de las tablas

```{r}
#rm(dataLog, quantity, sources)
dataLog  <- read_feather("featherFiles/dataLog.feather")
quantity <- read_feather("featherFiles/quantity.feather")
sources  <- read_feather("featherFiles/sources.feather")
```


### Contenido de las tablas

#### Datalog

```{r}
glimpse(dataLog)
```

#### Quantity

```{r}
glimpse(quantity)
```

#### Sources

```{r}
glimpse(sources)
```

#### Transformacion de datos para analisis previo

#### Union de tablas, borrado de columnas no importantes y Categorizacion de valores

```{r}
## Transformacion de columnas
dataLog$TimestampUTC <- as_datetime(dataLog$TimestampUTC)
dataLog$TimestampCR <- with_tz(dataLog$TimestampUTC, tzone = "America/Costa_Rica") 
dataLog$TimestampUTC <- NULL
dataLog$ID <- NULL
dataLog$year <- year(dataLog$TimestampCR)
dataLog$month <- month(dataLog$TimestampCR)
dataLog$day <- day(dataLog$TimestampCR)
dataLog$hour <- hour(dataLog$TimestampCR)
dataLog$minute <- minute(dataLog$TimestampCR)
dataLog$wday <- wday(dataLog$TimestampCR)
dataLog$wdayName <- weekdays(dataLog$TimestampCR)
dataLog$monthName <- factor(month.abb[dataLog$month])

dataLog$hour2 <- hour(dataLog$TimestampCR)+ (minute(dataLog$TimestampCR)/60)

dataLog <- dataLog %>% left_join(quantity, by = c('QuantityID' = "ID")) %>%
  left_join(sources, by = c('SourceID' = "ID"))

names(dataLog)[names(dataLog) == "Name.x"] <- "Quantity"
names(dataLog)[names(dataLog) == "Name.y"] <- "Meter"

dataLog$SourceID <- NULL
dataLog$QuantityID <- NULL
dataLog$DisplayName <- NULL
#rm(quantity, sources)
```

#### Contenido de la tabla Datalog

```{r}
glimpse(dataLog)
```

## Análisis de datos
### Histogramas y boxplots

#### Cantidad de filas inicial

```{r}
initial_rows <- nrow(dataLog)
initial_rows
```

#### Boxplot del comportamiento de la tension (horizontal)

```{r}
boxplot(dataLog$Value, xlab= "Voltaje", col="Orange", border = "brown", horizontal = T, main = "Voltaje Promedio") 
```

#### Histograma inicial

```{r}
hist(dataLog$Value, col="Orange", border = "brown", xlab = "Valor", ylab = "Frecuencia", main = "Histograma de Tension")

```

#### Variable temporal solo para análisis (originalmente se tenian 15825 rows)

```{r}
dl_temp <- dataLog %>% filter(Value > cut_voltage)
### Cantidad de filas
final_rows <- nrow(dl_temp)
print(paste0 ("Se eliminaron el ", round(100*((initial_rows - final_rows)/initial_rows), 2), "% de las filas" ))
```

#### Boxplot con un filtro temporal de los datos (para análisis unicamente)

```{r}
boxplot(dl_temp$Value, xlab= "Voltaje", col="Orange", border = "brown", horizontal = T, main = "Voltaje Promedio") 
```

#### Histograma eliminando outliers de la tabla temporal

```{r}
hist(dl_temp$Value, col="Orange", border = "brown", xlab = "Tension", ylab = "Frecuencia", breaks = 60, main = "Histograma de Tension")
```

#### Grafico de densidad

```{r}
d <- density(dl_temp$Value)
plot(d, main = "Densidad")
polygon(d, col = "Orange", border = "brown")
```

#### Boxplot separado por variable

```{r}

bp <- ggplot(dl_temp, aes(Quantity, Value))
bp <- bp + geom_boxplot(aes(colour = Quantity))
bp <- bp + scale_color_brewer(palette="Dark2")
bp

```

#### Grafico de densidad para cada variable

```{r}
lineas <- dl_temp %>% group_by(Quantity) %>% summarise(v = mean(Value))

p <- ggplot(dl_temp, aes(x=Value, fill = Quantity)) + 
  geom_density(alpha = 0.6) +
  geom_vline(data=lineas, aes(xintercept=v, color=Quantity), size = 2)
p
```

### Aqui inician la modificaciones reales de los datos

#### Pivot para generar columnas para las 3 variables de tension y eliminar los outliers

```{r}
dataLog2 <- tidyr::spread(dataLog, Quantity, Value)
dataLog2 <- dataLog2 %>% filter(Vab > cut_voltage, Vbc>cut_voltage, Vca > cut_voltage)
```

#### Muesta de la tabla

```{r}
head(dataLog2, 15)
```

### Cálculo del procentaje de desbalance

```{r}
unbal_calc  <- function(va, vb, vc){
  maximo =  pmax(abs(va-vb), abs(vb-vc), abs(vc-va))
  promedio = (va + vb + vc)/3
  unb <- 100*maximo/promedio


  return(unb)
}

unbal_categ  <- function(unb){
  unb_class <- case_when(unb < clasif["Low"] ~ "Low",
                      unb < clasif["Low_Mid"] ~ "Low_Mid",
                      unb < clasif["Mid"] ~ "Mid",
                      unb < clasif["Mid_High"] ~ "Mid_High",
                      unb < clasif["High"] ~ "High",
                      TRUE ~ "Very_High"
                      )
  return(unb_class)
} 

dataLog2 <- dataLog2 %>% 
  mutate (unbalance = unbal_calc(Vab, Vbc, Vca)) %>% 
  mutate (unbal_cat = factor(unbal_categ(unbalance), levels = c("Low","Low_Mid","Mid","Mid_High","High","Very_High"))) %>%
  select (year, monthName, day, hour, minute, wdayName, unbalance, unbal_cat)

glimpse(dataLog2)
table(dataLog2$unbal_cat)

```










#### Desbalance promedio 

```{r}
a <- dataLog2 %>% group_by(hour2) %>% summarise(v = mean(unbalance))
ggplot(a, aes(hour2, v)) + geom_point() + geom_line(col = "orange")

```

#### Desbalance a travez de los años

```{r}
a <- dataLog2 %>% group_by(year, hour2) %>% summarise(v = mean(unbalance))
ggplot(a, aes(hour2, v)) + geom_line(aes(colour = factor(year)), size=2)

```

## Particionamiento de los datos

```{r eval = FALSE}
dL <- dataLog2 %>% filter (year > 2018) %>% 
  select(wdayName, hour, unbalance) %>% 
  group_by(wdayName, hour) %>%
  summarise(unbalance = mean(unbalance)) %>%
  ungroup() %>%
  mutate(wdayName = as.factor(wdayName), hour = as.factor(hour))

set.seed(4)
mascara <- sample.split(dL$unbalance, SplitRatio = 7/10)
training_data <- dL[mascara,]
test_data <- dL[!mascara,]

glimpse(dL)

```

```{r}
modelo <- randomForest(formula = unbalance ~ ., data = training_data)

```


```{r}
pred <- predict(modelo, newdata = test_data)
test_data$pred <- pred

glimpse(test_data)

```

#### Evaluar el modelo

```{r}
confusionMatrix(test_data$unbalance, test_data$pred)
```











## Particionamiento de los datos

```{r eval = FALSE}
dL <- dataLog2 %>% filter (year > 2018) %>% 
  select(year, wdayName, hour, unbalance) %>% 
  group_by(year, wdayName, hour) %>%
  summarise(unbalance = mean(unbalance)) %>%
  ungroup() %>%
  mutate(wdayName = as.factor(wdayName), hour = as.factor(hour))

set.seed(4)
mascara <- sample.split(dL$unbalance, SplitRatio = 7/10)
training_data <- dL[mascara,]
test_data <- dL[!mascara,]

glimpse(dL)

```

```{r}
modelo <- randomForest(formula = unbalance ~ ., data = training_data)

```


```{r}
pred <- predict(modelo, newdata = test_data)
test_data$pred <- pred

glimpse(test_data)

```


#### F-Fold cross validation (evaluar con pequeños datasets)






##Diamonds graphics

```{r echo=F, message=F}
library(highcharter)
data(diamonds, mpg, package = "ggplot2")

hchart(mpg, "scatter", hcaes(x = displ, y = hwy, group = class))
hc_title(text="Some text here")
hc_add_theme(hc_theme_economist())

```





